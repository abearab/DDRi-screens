{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aims:** Extract results from the CRISPRi screen processing outputs and generate plots for the manuscript.\n",
    "\n",
    "- [ ] A table of the V3 data including the parent veh vs DNAPKi, KO veh vs DNAPKi, and parent veh vs KO veh comparisons (Table S3) - I will use this to replot the stuff in Fig 5\n",
    "- [ ] Some kind of QC plot for the V3 data - a PCA plot would be great if it looks okay and I'll put that in a supp figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup python session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y screenpro2\n",
    "# !pip install git+https://github.com/ArcInstitute/screenpro2.git@dev\n",
    "# # !pip install ScreenPro2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "import screenpro as scp\n",
    "import blitzgsea as blitz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sc.settings.set_figure_params(\n",
    "    dpi=150, format='svg', frameon=False, figsize=(3, 3), color_map='RdGy', \n",
    "    facecolor='white', \n",
    "    vector_friendly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import font_manager as fm\n",
    "from matplotlib import rcParams, rc_context\n",
    "\n",
    "from screenpro.plotting._utils import almost_black, dark2\n",
    "\n",
    "\n",
    "matplotlib.use('cairo')\n",
    "\n",
    "font_files = fm.findSystemFonts(fontpaths='/home/abea/miniconda3/envs/screenpro2/fonts/', fontext='ttf')\n",
    "\n",
    "for font_file in font_files:\n",
    "    fm.fontManager.addfont(font_file)\n",
    "\n",
    "\n",
    "# {f.name for f in matplotlib.font_manager.fontManager.ttflist}\n",
    "\n",
    "rcParams['font.sans-serif'] = 'Helvetica'\n",
    "rcParams['font.family'] = ['Helvetica']\n",
    "rcParams['figure.dpi'] = 140\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_names = {\n",
    "    'Pi': 'PARPi',\n",
    "    'Ri': 'ATRi',\n",
    "    'Wi': 'WEE1i',\n",
    "    'Mi': 'ATMi',\n",
    "    'Ki': 'DNAPKi',\n",
    "    'PiRi': 'PARPi+ATRi',\n",
    "    'PiWi': 'PARPi+WEE1i',\n",
    "    'PiMi': 'PARPi+ATMi',\n",
    "    'PiKi': 'PARPi+DNAPKi'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract result tables from screen object\n",
    "def extract_result_tables(screen):\n",
    "    result_tables = []\n",
    "\n",
    "    for phenotype_name in screen.listPhenotypeScores(run_name='compare_guides'):\n",
    "        if 'rho' in phenotype_name:\n",
    "            result_tables.append((phenotype_name,\n",
    "                screen.getPhenotypeScores(\n",
    "                    run_name='compare_guides', phenotype_name=phenotype_name,\n",
    "                    pvalue_col = 'ttest pvalue',\n",
    "                    threshold=6\n",
    "                ).query('target!=\"negative_control\"').set_index(['target','transcript'])\n",
    "            ))\n",
    "        \n",
    "    result_tables = dict(result_tables)\n",
    "\n",
    "    return result_tables\n",
    "\n",
    "\n",
    "### get result tables: gene level scores with out negative controls\n",
    "def getAnnotatedTables(screen, run_name, threshold):\n",
    "    return dict([\n",
    "        (phenotype_name, \n",
    "         screen.getPhenotypeScores(\n",
    "             run_name=run_name,phenotype_name=phenotype_name,threshold=threshold, pvalue_col='ttest pvalue'\n",
    "         ).query('target!=\"negative_control\"').reset_index().rename(columns={'index':'sgID_AB'}).set_index(\n",
    "             ['sgID_AB','target','transcript'])\n",
    "            )\n",
    "        for phenotype_name in screen.listPhenotypeScores(run_name=run_name)\n",
    "    ])\n",
    "\n",
    "\n",
    "### get annotated result table: rho scores\n",
    "def get_annotated_result_table(screen, run_name, name_it = '', threshold=6):\n",
    "    return pd.concat(dict([\n",
    "        # (drug_names[k.split(':')[1].split('_vs_')[0]],table) for k, table in \n",
    "        (name_it + k.split(':')[1],table) for k, table in \n",
    "        getAnnotatedTables(screen,threshold=threshold,run_name=run_name).items()\n",
    "        if 'rho' in k\n",
    "    ]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pathway analysis\n",
    "pager_dir = \"/home/abea/tools/pager/\"\n",
    "pager_annotation_path = '/home/abea/tools/pager/annotations/human'\n",
    "\n",
    "c5_gobp_gmt = blitz.enrichr.read_gmt(\n",
    "    f'{pager_annotation_path}/msigdb_v7.4_c5.go.bp/c5.go.bp.v7.4.symbols.gmt'\n",
    ")\n",
    "\n",
    "\n",
    "def run_rho_gsea_directional(df,var_col,gmt,min_size=15,max_size=150):\n",
    "    signature = df[var_col].reset_index().drop(columns=['transcript','sgID_AB']).copy()\n",
    "\n",
    "    result = blitz.gsea(\n",
    "        signature=signature,\n",
    "        library=gmt,\n",
    "        min_size=min_size,\n",
    "        max_size=max_size,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return signature, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load Screen Processing guide level and gene level result tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "crispri_v3_adata = sc.read_h5ad('screens/A549_PRDX1_CRISPRi_v3.h5ad.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "crispri_v3_screen = scp.load._read_screen_pkl('screens/A549_PRDX1_CRISPRi_v3_screens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['compare_reps_parent', 'compare_reps_PRDX1KO', 'compare_reps_vehicle'])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crispri_v3_screen.phenotypes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat(),axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['compare_reps_parent', 'compare_reps_PRDX1KO', 'compare_reps_vehicle'])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crispri_v3_screen.phenotypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "crispri_v3_screen_result_tables = pd.concat([\n",
    "    get_annotated_result_table(\n",
    "        crispri_v3_screen,run_name='compare_reps_PRDX1KO', name_it='PRDX1KO__'\n",
    "    ),\n",
    "    get_annotated_result_table(\n",
    "        crispri_v3_screen,run_name='compare_reps_parent', name_it='parent__'\n",
    "    ),\n",
    "\n",
    "    get_annotated_result_table(\n",
    "        crispri_v3_screen,run_name='compare_reps_vehicle', name_it='vehicle__'\n",
    "    )\n",
    "],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRDX1KO__DNAPKi_vs_vehicle', 'parent__DNAPKi_vs_vehicle',\n",
       "       'vehicle__PRDX1KO_vs_parent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crispri_v3_screen_result_tables.columns.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRDX1KO__DNAPKi_vs_vehicle\n",
      "Use cached anchor parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrichment : 100%|██████████| 7481/7481 [00:01<00:00, 6352.30it/s]\n",
      "/home/abea/miniconda3/envs/screenpro2/lib/python3.11/site-packages/statsmodels/stats/multitest.py:164: RuntimeWarning: divide by zero encountered in log1p\n",
      "  pvals_corrected = -np.expm1(ntests * np.log1p(-pvals))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent__DNAPKi_vs_vehicle\n",
      "Use cached anchor parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrichment : 100%|██████████| 7481/7481 [00:01<00:00, 6410.94it/s]\n",
      "/home/abea/miniconda3/envs/screenpro2/lib/python3.11/site-packages/statsmodels/stats/multitest.py:164: RuntimeWarning: divide by zero encountered in log1p\n",
      "  pvals_corrected = -np.expm1(ntests * np.log1p(-pvals))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle__PRDX1KO_vs_parent\n",
      "Use cached anchor parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enrichment : 100%|██████████| 7481/7481 [00:01<00:00, 6526.69it/s]\n",
      "/home/abea/miniconda3/envs/screenpro2/lib/python3.11/site-packages/statsmodels/stats/multitest.py:164: RuntimeWarning: divide by zero encountered in log1p\n",
      "  pvals_corrected = -np.expm1(ntests * np.log1p(-pvals))\n"
     ]
    }
   ],
   "source": [
    "crispri_v3_screen_gsea_results = {}\n",
    "\n",
    "for comparison in crispri_v3_screen_result_tables.columns.get_level_values(0).unique():\n",
    "\n",
    "    print(comparison)\n",
    "    \n",
    "    _, res = run_rho_gsea_directional(\n",
    "        crispri_v3_screen_result_tables[comparison].dropna(),\n",
    "        var_col='score', \n",
    "        gmt=c5_gobp_gmt\n",
    "    )\n",
    "\n",
    "    crispri_v3_screen_gsea_results[comparison] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "? how we want to organize the results for the manuscript tables (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter('CRISPRi-PRDX1-DDRi-screens.xlsx', engine='openpyxl') as writer:\n",
    "#     screen.adata.obs.to_excel(writer, sheet_name='sample sheet')\n",
    "#     screen.adata.to_df(layer='raw_counts').astype(int).T.to_excel(writer, sheet_name='raw counts')\n",
    "#     screen.adata.to_df(layer='seq_depth_norm').astype(int).T.to_excel(writer, sheet_name='normalized counts')\n",
    "#     getAnnotatedTable(screen_parent, threshold=2).to_excel(writer, sheet_name='parent screen')\n",
    "#     getAnnotatedTable(screen_PRDX1KO, threshold=2).to_excel(writer, sheet_name='PRDX1KO screen')\n",
    "#     getAnnotatedTable(screen_vehicle, threshold=2)[['rho:PRDX1KO_vs_parent']].to_excel(writer, sheet_name='vehicle screen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('tables/Table-S3.xlsx', engine='openpyxl') as writer:\n",
    "    crispri_v3_screen_result_tables.to_excel(writer, sheet_name='Gene Level Phenotypes')\n",
    "    pd.concat(crispri_v3_screen_gsea_results,axis=1).to_excel(writer, sheet_name='GO GSEA Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-09-25T00:59:44.332049-07:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 8.27.0\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.0-119-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 64\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas    : 1.5.3\n",
      "matplotlib: 3.6.2\n",
      "scanpy    : 1.10.3\n",
      "blitzgsea : 1.3.47\n",
      "screenpro : 0.4.15\n",
      "numpy     : 1.26.4\n",
      "anndata   : 0.10.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "screenpro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
